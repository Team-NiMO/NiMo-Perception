#!/usr/bin/env python3

# -*- encoding: utf-8 -*-

import math
import os
import signal
import subprocess
from typing import Optional, Any

import cv2 as cv
import numpy as np
import open3d as o3d
import pyransac3d as pyrsc
import rospy
from cv_bridge import CvBridge
from geometry_msgs.msg import Point, Vector3, Pose2D
from message_filters import ApproximateTimeSynchronizer
from sensor_msgs.msg import CameraInfo, Image
from termcolor import colored

from stalk_detect.config import (BEST_STALK_ALGO, CAMERA_INFO, DEPTH_SCALE,
                                 DEPTH_TOPIC, DEPTH_TRUNC, DRIVER_COMMAND,
                                 FEATURE_POINT_PIXEL_OFFSET,
                                 GRASP_POINT_ALGO, GRIPPER_LENGTH_PAST_STALK, GRIPPER_WIDTH,
                                 IMAGE_TOPIC, INLIER_THRESHOLD,
                                 MAX_RANSAC_ITERATIONS, MINIMUM_MASK_AREA,
                                 RUN_REALSENSE_ON_REQUEST, SERVICE_REQUEST_END_BUFFER_TIME, VISUALIZE,
                                 BestStalkOptions, GraspPointFindingOptions, VERBOSE, SAVE_IMAGES)
from stalk_detect.model import MaskRCNN
from stalk_detect.srv import (GetStalk, GetStalkRequest, GetStalkResponse,
                             GetWidth, GetWidthRequest, GetWidthResponse)
from stalk_detect.msg import grasp_point as grasp_msg
from stalk_detect.transforms import TfBuffer, Transformer
from stalk_detect.utils import KillableSubscriber, Stalk, ransac_2d
from stalk_detect.visualize import Visualizer

class DetectNode:
    @classmethod
    def __init__(cls):
        if VERBOSE: rospy.loginfo('Starting stalk_detect node.')

        cls.model = MaskRCNN()
        cls.cv_bridge = CvBridge()
        cls.visualizer = Visualizer()
        cls.tf_buffer = TfBuffer()

        cls.call_index = -1  # Total service calls
        cls.image_index = -1 # Images in current service call

        cls.driver_process = None

        # Setup services
        cls.get_stalk_service = rospy.Service('get_stalk', GetStalk, cls.find_stalk)
        cls.get_stalk_service = rospy.Service('get_width', GetWidth, cls.find_width)

        # Check camera connection
        try:
            rospy.wait_for_message(CAMERA_INFO, CameraInfo, timeout=5)
        except rospy.ROSException:
            rospy.logwarn('Camera info not found, so camera is likely not running!', 'yellow')

        if VERBOSE: rospy.loginfo('Waiting for service calls...')

    @classmethod
    def run_detection(cls, image):
        '''
        Run the Mask R-CNN model on the given image

        Parameters
            image (sensor_msgs.msg.Image): The image to run the model on

        Returns
            masks (np.ndarray): The masks of the detected stalks
            output (np.ndarray): The output image of the model
            scores (np.ndarray): The scores of the detected stalks
        '''
        cv_image = cls.cv_bridge.imgmsg_to_cv2(image, desired_encoding='bgr8')

        # Run the model
        scores, _, masks, output = cls.model.forward(cv_image)
        masks = masks.astype(np.uint8) * 255

        return masks, output, scores

    @classmethod
    def get_features(cls, masks) -> 'list[list[Pose2D]]':
        '''
        Get the center points going up each stalk

        Parameters
            masks (np.ndarray): The masks of the detected stalks

        Returns
            stalks_features (list[list[Pose2D]]): The center points and depths of the stalks, for each stalk
        '''
        # Get the center points of the stalks
        stalks_features = []
        for mask in masks:
            # Ensure the mask has the minimum number of pixels
            if np.count_nonzero(mask) < MINIMUM_MASK_AREA:
                continue

            # Swap x and y in the mask
            mask = np.swapaxes(mask, 0, 1)
            nonzero = np.nonzero(mask)

            # Get the top and bottom height values of the stalk
            # NOTE: bottom_y is the top of the mask in the image using openCV indexing
            top_y, bottom_y = nonzero[1].min(), nonzero[1].max()

            stalk_features = [Pose2D(x=np.nonzero(mask[:, top_y])[0].mean(), y=top_y)]

            # For every FEATURE_POINT_PIXEL_OFFSET pixels, get the center point
            for y in range(top_y, bottom_y, FEATURE_POINT_PIXEL_OFFSET):
                # Find the average x value for nonzero pixels at this y value
                y_values = np.nonzero(mask[:, y])[0]

                # If there are no y pixels, simply skip this value
                if len(y_values) > 0:
                    stalk_features.append(Pose2D(x=y_values.mean(), y=y))

            stalk_features.append(Pose2D(x=np.nonzero(mask[:, bottom_y])[0].mean(), y=bottom_y))

            stalks_features.append(stalk_features)

        return stalks_features
    
    @classmethod
    def get_widths(cls, stalks_features, masks, cv_depth_image):
        stalk_widths = []
        for i, stalk_features in enumerate(stalks_features):
                if len(stalk_features) == 0:
                    continue

                slope, _, _ = ransac_2d(stalk_features)
                perp_slope = -1 / slope

                mask = masks[i]
                nonzero = np.nonzero(mask)
                x0 = nonzero[1].min() # MIN X
                y1 = nonzero[0].min() # MIN Y
                x2 = nonzero[1].max() # MAX X
                x3, y3 = (nonzero[1][np.argmax(nonzero[0])], nonzero[0].max()) # MAX Y AND CORRESPONDING X

                widths = []
                px_widths = []
                # Loop bottom to top of mask
                max_y = int(y1 - abs((x0-x2) * perp_slope))
                min_y = int(y3 + abs((x0-x2) * perp_slope))
                for i in range(min_y, max_y, -1): # MOTIVATE Y LIMITS BY NECESSARY X VALUES
                    # Loop across every line
                    count = 0
                    depths = []
                    for j in range(x0-x2, x2-x0):
                        test_x, test_y = (int(j + x3), int(i + perp_slope * j))
                        try:
                            if mask[test_y, test_x]:
                                mask[test_y, test_x] = 125
                                count += 1
                                if cv_depth_image[test_y, test_x] != 0:
                                    depths.append(cv_depth_image[test_y, test_x])
                        except:
                            pass
                    if count > 0 and len(depths) > 0:
                        widths.append(count * np.median(depths) * 0.0036) # MAGIC NUM FIX LATER
                        px_widths.append(count)

                rospy.loginfo("Median Width = {} mm".format(np.median(widths)))
                rospy.loginfo("Median Width = {} px".format(np.median(px_widths)))
                stalk_widths.append(np.median(widths))

        return stalk_widths


    @classmethod
    def determine_best_stalk(cls, positions: 'list[Point]', weights) -> Point:
        '''
        Find the best stalk from a list of positions.

        Parameters
            positions (list): A list of positions to cluster and average

        Returns
            (geometry_msgs.msg.Point): The best grasping point
        '''
        def distance(point1: Point, point2: Point):
            return math.sqrt((point1.x - point2.x)**2 + (point1.y - point2.y)**2)

        # Only store the X and Y values of the positions
        # clustering = OPTICS(eps=0.1, metric=distance).fit(stalks)
        THRESHOLD = 0.1
        clustering_labels = [0]
        for position in positions[1:]:
            min_distance = float('inf')
            min_cluster = 0
            for i in range(len(clustering_labels)):
                if distance(position, positions[i]) < min_distance:
                    min_distance = distance(position, positions[i])
                    min_cluster = clustering_labels[i]

            clustering_labels.append(min_cluster if min_distance < THRESHOLD else max(clustering_labels) + 1)

        clustering_labels = np.array(clustering_labels)

        # Combine clusters
        stalks = []
        stalk_weights = []
        for label in np.unique(clustering_labels):
            points = np.array(positions)[np.nonzero(clustering_labels == label)]
            avg = Point(x=np.mean([point.x for point in points]),
                        y=np.mean([point.y for point in points]),
                        z=np.mean([point.z for point in points]))
            
            cluster_weights = np.array(weights)[np.nonzero(clustering_labels == label)]
            weights_avg = np.mean(cluster_weights)

            stalks.append(avg)
            stalk_weights.append(weights_avg)

        # Sort representative stalks by weight
        sorted_stalks = [x for _, x in sorted(zip(stalk_weights, stalks), reverse=True)]

        return sorted_stalks, stalk_weights

    @classmethod
    def get_pcl(cls, image, depth_image, transformer):
        '''
        Get the point cloud

        Parameters
            image (openCV Image): The image
            depth_image (openCV Image): The depth image

        Returns
            point_cloud (pcl PointCloud): The point cloud
        '''
        pcd = o3d.geometry.PointCloud.create_from_rgbd_image(
            o3d.geometry.RGBDImage.create_from_color_and_depth(
                o3d.geometry.Image(cls.cv_bridge.imgmsg_to_cv2(image, desired_encoding='bgr8')),
                o3d.geometry.Image(cls.cv_bridge.imgmsg_to_cv2(depth_image, desired_encoding='mono8')),
                depth_scale=DEPTH_SCALE, depth_trunc=DEPTH_TRUNC, convert_rgb_to_intensity=False),
            o3d.camera.PinholeCameraIntrinsic(
                transformer.width, transformer.height, transformer.intrinsic))

        return pcd

    @classmethod
    def transform_points_to_world(cls, stalks_features: 'list[list[Point]]', transformer: Transformer) -> 'list[list[Point]]':
        '''
        Transform the stalk features to the ground plane (using the robot base transform)

        Parameters
            stalk_features (list[list[Point]]): The center points of the stalks
            transformer (Transformer): The transformer

        Returns
            transformed_features (list[list[Point]]): The transformed features
        '''
        transformed_features = []
        for stalk in stalks_features:
            transformed_features.append([transformer.transform_cam_to_world(p) for p in stalk])

        return transformed_features

    @classmethod
    def run_realsense(cls):
        cls.driver_process = subprocess.Popen(DRIVER_COMMAND, stdout=subprocess.PIPE, shell=True, preexec_fn=os.setsid)

    @classmethod
    def stop_realsense(cls):
        if cls.driver_process is not None:
            os.killpg(os.getpgid(cls.driver_process.pid), signal.SIGTERM)
            cls.driver_process = None

    @classmethod
    def find_stalk(cls, req: GetStalkRequest) -> GetStalkResponse:
        '''
        Determine the suitable stalks within view

        Parameters
            req (GetStalkRequest): The request: 
                                   - num_frames - The number of frames to process
                                   - timeout - the timeout in seconds to wait until aborting

        Returns
            GetStalkResponse: The response:
                              - success - The success of the operation (SUCCESS / REPOSITION / ERROR)
                              - num_frames - The number of frames processed
                              - grasp_points - A list of grasp points on the cornstalks ordered from best to worst
        '''
        
        if VERBOSE: rospy.loginfo('Received a request for {} frames with timeout {} seconds'.format(req.num_frames, req.timeout))
        
        cls.call_index += 1 # Increment the number of calls

        # Run the realsense camera driver if needed
        if RUN_REALSENSE_ON_REQUEST:
            cls.run_realsense()

        try:
            camera_info = rospy.wait_for_message(CAMERA_INFO, CameraInfo, timeout=2)
            if camera_info is None:
                raise rospy.ROSException
            cls.camera_height = camera_info.height
            cls.camera_width = camera_info.width
        except rospy.ROSException:
            rospy.logerr('Camera info not found, so camera is likely not running!', 'red')
            return GetStalkResponse(success='ERROR', num_frames=0)

        cls.image_index = -1
        start = rospy.get_rostime()
        positions: list[Point] = []
        weights = []
        transformers: list[Transformer] = []

        def image_depth_callback(image, depth_image):
            nonlocal positions, transformers, weights

            transformer = Transformer(cls.tf_buffer.get_tf_buffer())

            cls.image_index += 1 # Incrememnt the number of images

            if VERBOSE: rospy.loginfo("Image {} / {} captured".format(cls.image_index, req.num_frames))

            cv_depth_image = cls.cv_bridge.imgmsg_to_cv2(depth_image, desired_encoding="passthrough")
            cv_depth_image = np.array(cv_depth_image, dtype=np.float32)
            cv_image = cls.cv_bridge.imgmsg_to_cv2(image, desired_encoding='rgb8')

            # Save image, masked image, mask, and depth image
            if SAVE_IMAGES:
                cv.imwrite('output/MASKED{}-{}.png'.format(cls.call_index, cls.image_index), cls.model.visualize(cv.cvtColor(cv_image, cv.COLOR_RGB2BGR, cv_image), output).astype(np.uint8))
                cv.imwrite('output/IMAGE{}-{}.png'.format(cls.call_index, cls.image_index), cv_image)
                cv.imwrite('output/DEPTH{}-{}.png'.format(cls.call_index, cls.image_index), cv_depth_image)
                np.save('output/MASK{}-{}.png'.format(cls.call_index, cls.image_index), masks)

            # Run model, extract features, get widths
            masks, output, scores = cls.run_detection(image)
            stalks_features: list[list[Any]] = cls.get_features(masks)
            stalk_widths = cls.get_widths(stalks_features, masks, cv_depth_image)

            # Visualize the stalks features on the image
            if VISUALIZE:
                features_image = cls.model.visualize(cv.cvtColor(cv_image, cv.COLOR_RGB2BGR, cv_image), output).astype(np.uint8)
                for stalk in stalks_features:
                    for point in stalk:
                        try:
                            cv.circle(features_image, (int(point.x), int(point.y)), 2, (0, 0, 255), -1)
                        except Exception as e:
                            print('Unable to put circle in stalk image', e)
                            break
                cls.visualizer.publish_item('masks', features_image)
                # cv.imwrite('masks/output{}-{}.png'.format(cls.call_index, cls.image_index), features_image)

            # Add the depths to the stalk features
            for i, stalk in enumerate(stalks_features):
                for j in range(len(stalk)):
                    # TODO: Use more pixels from the depth image to get a better depth (only if they are in the mask)

                    # Get the depth from the depth image at this point
                    stalks_features[i][j] = Point(x=cls.camera_width - stalk[j].x, y=cls.camera_height - stalk[j].y,
                                                  z=cv_depth_image[int(stalk[j].y), int(stalk[j].x)] / DEPTH_SCALE)

            stalks_features = cls.transform_points_to_world(stalks_features, transformer)

            # Turn these features into stalks
            stalks = []
            for stalk, score, mask, width in zip(stalks_features, scores, masks, stalk_widths):
                new_stalk = Stalk(points=stalk, score=score, mask=mask, width=width)

                # Ensure the stalk is valid, in case RANSAC failed
                if new_stalk.is_valid():
                    stalks.append(new_stalk)
            
            if VISUALIZE and len(stalks_features):
                cls.visualizer.new_frame()
                cls.visualizer.publish_item('features', stalks_features, marker_color=[255, 0, 0])
                for stalk in stalks:
                    cls.visualizer.publish_item('stalk_lines', stalk, marker_color=[255, 255, 0], marker_size=0.01)

            if GRASP_POINT_ALGO == GraspPointFindingOptions.mask_only:
                for stalk in stalks:
                    stalk.set_grasp_point(min_height=min([p.z for p in stalk.points]))
            elif GRASP_POINT_ALGO == GraspPointFindingOptions.mask_projection:
                for stalk in stalks:
                    stalk.set_grasp_point(min_height=0)
            else:
                raise ValueError('Invalid grasp point finding algorithm')

            # Set the camera grasping points
            for stalk in stalks:
                stalk.set_cam_grasp_point(transformer.transform_world_to_cam(stalk.grasp_point))

            # Filter out stalks that are not within the bounds of the camera
            valid_stalks: list[Stalk] = [s for s in stalks if s.is_within_bounds()]

            if len(valid_stalks) == 0:
                rospy.logwarn('No valid stalks detected on frame {} ({} total stalks found)'.format(cls.image_index, len(stalks)))
                cls.stop_realsense()
                return

            if BEST_STALK_ALGO == BestStalkOptions.largest:
                best_stalk = max(valid_stalks, key=lambda stalk: np.count_nonzero(stalk.mask))

            elif BEST_STALK_ALGO == BestStalkOptions.largest_favorable:
                cv.imwrite('masks/{}.png'.format(cls.image_index), features_image)
                rospy.loginfo('IMAGE {}: y coords {}'.format(cls.image_index, [s.cam_grasp_point.y for s in valid_stalks]))

            graspable_stalks: list[Stalk] = []

            # Order by grasping point coordinates instead of masks, to account for possible sporadic points
            ordered_right_to_left: list[Stalk] = sorted(valid_stalks, key=lambda stalk: stalk.cam_grasp_point.y)

            # Note that we do not need to worry about stalks far on the right side of the frame, since they'll be eliminated earlier

            # Iterate from the right to the left, eliminating stalks that are too close for the gripper to fit between
            graspable_stalks.append(ordered_right_to_left[0])
            for i in range(1, len(ordered_right_to_left)):
                is_free = True
                for j in range(0, i):
                    # NOTE: Temporary
                    assert ordered_right_to_left[i].cam_grasp_point.y >= ordered_right_to_left[j].cam_grasp_point.y

                    # if ordered_right_to_left[i].cam_grasp_point.y - ordered_right_to_left[j].cam_grasp_point.y < GRIPPER_WIDTH and \
                    #         ordered_right_to_left[j].cam_grasp_point.x - ordered_right_to_left[i].cam_grasp_point.x < GRIPPER_LENGTH_PAST_STALK:
                    #     is_free = False
                    #     break

                    # Filter out stalks of unsuitable width
                    if ordered_right_to_left[i].width < 12 or ordered_right_to_left[i].width > 45:
                        is_free = False
                        break

                if is_free:
                    graspable_stalks.append(ordered_right_to_left[i])

            # For the remaining stalks, weight by width, confidence, and height
            stalk_weights = []
            for i, stalk in enumerate(graspable_stalks):
                mask_height = np.ptp([p.z for p in stalk.points]) # Use the z coordinate in world frame
                distance_from_center = abs(stalk.cam_grasp_point.y) # Use the y coordinate in camera frame

                weight = (stalk.score ** 2) * stalk.width * (math.pow(mask_height, 1/3)) * (1 - distance_from_center)

                if VERBOSE: rospy.loginfo('Stalk index {} has weight {}, score {}, height {}, width {} distance_from_center {} y {}'.format(
                        i, weight, stalks[i].score, mask_height, stalk.width, distance_from_center, stalk.cam_grasp_point.y))

                stalk_weights.append(weight)

            best_stalk = graspable_stalks[np.argmax(stalk_weights)]


            if VISUALIZE:
                    cls.visualizer.publish_item('grasp_points', [best_stalk.grasp_point], marker_color=[255, 0, 255], marker_size=0.02)

            if BEST_STALK_ALGO in [BestStalkOptions.largest, BestStalkOptions.largest_favorable]:
                for stalk, weight in zip(graspable_stalks, stalk_weights):
                    positions.append(transformer.transform_world_to_cam(stalk.grasp_point))
                    weights.append(weight)

        # Setup the callback for the images and depth images
        cls.sub_images = KillableSubscriber(IMAGE_TOPIC, Image)
        cls.sub_depth = KillableSubscriber(DEPTH_TOPIC, Image)
        ts = ApproximateTimeSynchronizer([cls.sub_images, cls.sub_depth], queue_size=5, slop=0.2)
        ts.registerCallback(image_depth_callback)

        # Continue until enough frames have been gathered, or the timeout has been reached
        while cls.image_index < req.num_frames and (rospy.get_rostime() - start).to_sec() + SERVICE_REQUEST_END_BUFFER_TIME < req.timeout:
            rospy.sleep(0.1)

        # Unregister the callback
        cls.sub_depth.unregister()
        cls.sub_images.unregister()
        del ts

        #  Cluster the positions, find the best one, average it
        if len(positions) == 0:
            rospy.logwarn('No valid stalks detected in any frame for this service request, requesting a REPOSITION')
            cls.stop_realsense()
            return GetStalkResponse(success='REPOSITION', num_frames=cls.image_index + 1)

        # Option 1 or 2.1: Simply find the consensus among the individual decisions
        if BEST_STALK_ALGO in [BestStalkOptions.largest, BestStalkOptions.largest_favorable]:
            try:
                clustered_stalks, clustered_weights = cls.determine_best_stalk(positions, weights)
            except Exception:
                rospy.logwarn('Best stalk determination failed, so using only the first frame')
        else:
            raise ValueError('Invalid best stalk algorithm')

        # Package grasp points for message
        grasp_msgs = []
        for stalk, weight in zip(clustered_stalks, clustered_weights):
            grasp_msgs.append(grasp_msg(position=stalk, weight=weight))

        # Stop the camera driver
        cls.stop_realsense()
        return GetStalkResponse(success='DONE', grasp_points=grasp_msgs, num_frames=cls.image_index + 1)
    
    @classmethod
    def find_width(cls, req: GetWidthRequest) -> GetWidthResponse:
        '''
        Determine the width of a cornstalk

        Parameters
            req (GetStalkRequest): The request: 
                                   - num_frames - The number of frames to process
                                   - timeout - the timeout in seconds to wait until aborting

        Returns
            GetStalkResponse: The response:
                              - success - The success of the operation (SUCCESS / REPOSITION / ERROR)
                              - num_frames - The number of frames processed
                              - width - The width of the cornstalk in mm
        '''
        
        if VERBOSE: rospy.loginfo('Received a request for {} frames with timeout {} seconds'.format(req.num_frames, req.timeout))
        
        cls.call_index += 1 # Increment the number of calls

        # Run the realsense camera driver if needed
        if RUN_REALSENSE_ON_REQUEST:
            cls.run_realsense()

        try:
            camera_info = rospy.wait_for_message(CAMERA_INFO, CameraInfo, timeout=2)
            if camera_info is None:
                raise rospy.ROSException
            cls.camera_height = camera_info.height
            cls.camera_width = camera_info.width
        except rospy.ROSException:
            rospy.logerr('Camera info not found, so camera is likely not running!', 'red')
            return GetStalkResponse(success='ERROR', num_frames=0)

        cls.image_index = -1
        start = rospy.get_rostime()
        stalk_widths: list[float] = []

        # NOTE: ASSUMES ONLY ONE CORNSTALK IN FRAME -> NEED TO CONSIDER CONDITIONS FOR MULTIPLE CORNSTLALKS
        def image_depth_callback(image, depth_image):

            cls.image_index += 1 # Incrememnt the number of images

            if VERBOSE: rospy.loginfo("Image {} / {} captured".format(cls.image_index, req.num_frames))

            cv_depth_image = cls.cv_bridge.imgmsg_to_cv2(depth_image, desired_encoding="passthrough")
            cv_depth_image = np.array(cv_depth_image, dtype=np.float32)
            cv_image = cls.cv_bridge.imgmsg_to_cv2(image, desired_encoding='rgb8')

            # Save image, masked image, mask, and depth image
            if SAVE_IMAGES:
                cv.imwrite('output/MASKED{}-{}.png'.format(cls.call_index, cls.image_index), cls.model.visualize(cv.cvtColor(cv_image, cv.COLOR_RGB2BGR, cv_image), output).astype(np.uint8))
                cv.imwrite('output/IMAGE{}-{}.png'.format(cls.call_index, cls.image_index), cv_image)
                cv.imwrite('output/DEPTH{}-{}.png'.format(cls.call_index, cls.image_index), cv_depth_image)
                np.save('output/MASK{}-{}.png'.format(cls.call_index, cls.image_index), masks)

            # Run model, extract features, get widths
            masks, output, _ = cls.run_detection(image)
            stalks_features = cls.get_features(masks)
            widths = cls.get_widths(stalks_features, masks, cv_depth_image)

            for width in widths:
                stalk_widths.append(width)

        # Setup the callback for the images and depth images
        cls.sub_images = KillableSubscriber(IMAGE_TOPIC, Image)
        cls.sub_depth = KillableSubscriber(DEPTH_TOPIC, Image)
        ts = ApproximateTimeSynchronizer(
            [cls.sub_images, cls.sub_depth], queue_size=5, slop=0.2)
        ts.registerCallback(image_depth_callback)

        # Continue until enough frames have been gathered, or the timeout has been reached
        while cls.image_index < req.num_frames and (rospy.get_rostime() - start).to_sec() + SERVICE_REQUEST_END_BUFFER_TIME < req.timeout:
            rospy.sleep(0.1)

        # Unregister the callback
        cls.sub_depth.unregister()
        cls.sub_images.unregister()
        del ts

        #  Cluster the positions, find the best one, average it
        if len(stalk_widths) == 0:
            rospy.logwarn('No valid stalks detected on frame {} ({} total stalks found)'.format(cls.image_index, len(stalks)))
            cls.stop_realsense()
            return GetWidthResponse(success='REPOSITION', num_frames=cls.image_index + 1)

        # Stop the camera driver
        cls.stop_realsense()
        return GetWidthResponse(success='DONE', width=np.average(stalk_widths), num_frames=cls.image_index + 1)

if __name__ == '__main__':
    rospy.init_node('stalk_detect')
    detect_node = DetectNode()
    rospy.spin()
