#!/usr/bin/env python3

# -*- encoding: utf-8 -*-

import math
import os
import signal
import subprocess

import cv2 as cv
import numpy as np
import open3d as o3d
import pyransac3d as pyrsc
import rospy
from cv_bridge import CvBridge
from geometry_msgs.msg import Point, Vector3
from message_filters import ApproximateTimeSynchronizer
from sensor_msgs.msg import CameraInfo, Image
from termcolor import colored

from stalk_detect.config import (CAMERA_INFO, DEPTH_SCALE,
                                 DEPTH_TOPIC, DEPTH_TRUNC, DRIVER_COMMAND,
                                 FEATURE_POINT_PIXEL_OFFSET,
                                 GRIPPER_LENGTH_PAST_STALK, GRIPPER_WIDTH,
                                 IMAGE_TOPIC, INLIER_THRESHOLD,
                                 MAX_RANSAC_ITERATIONS, MINIMUM_MASK_AREA,
                                 RUN_REALSENSE_ON_REQUEST, SERVICE_REQUEST_END_BUFFER_TIME, VISUALIZE)
from stalk_detect.model import MaskRCNN
from stalk_detect.srv import GetStalk, GetStalkRequest, GetStalkResponse
from stalk_detect.msg import stalk as stalk_msg, line as line_msg
from stalk_detect.transforms import TfBuffer, Transformer
from stalk_detect.utils import KillableSubscriber, Stalk
from stalk_detect.visualize import Visualizer


class DetectNode:
    @classmethod
    def __init__(cls):
        cls.model = MaskRCNN()
        cls.cv_bridge = CvBridge()

        cls.visualizer = Visualizer()

        cls.tf_buffer = TfBuffer()

        cls.get_stalk_service = rospy.Service('get_stalk', GetStalk, cls.find_stalk)

        try:
            rospy.wait_for_message(CAMERA_INFO, CameraInfo, timeout=5)
        except rospy.ROSException:
            print(colored('Camera info not found, so camera is likely not running!', 'yellow'))

        # Count the number of total service calls (for visualization, etc)
        cls.call_index = -1

        # Count the number of images processed in the current service call
        cls.image_index = -1

        cls.driver_process = None

    @classmethod
    def run_detection(cls, image):
        '''
        Run the Mask R-CNN model on the given image

        Parameters
            image (sensor_msgs.msg.Image): The image to run the model on

        Returns
            masks (np.ndarray): The masks of the detected stalks
            output (np.ndarray): The output image of the model
            scores (np.ndarray): The scores of the detected stalks
        '''
        cv_image = cls.cv_bridge.imgmsg_to_cv2(image, desired_encoding='bgr8')

        cv.imwrite('masks/input_{}-{}.png'.format(cls.call_index, cls.image_index), cv_image)

        # Run the model
        scores, bboxes, masks, output = cls.model.forward(cv_image)
        masks = masks.astype(np.uint8) * 255

        return masks, output, scores

    @classmethod
    def get_features(cls, masks, depth_image) -> 'list[list[Point]]':
        '''
        Get the center points going up each stalk

        Parameters
            masks (np.ndarray): The masks of the detected stalks

        Returns
            stalks_features (list[list[Point]]): The center points and depths of the stalks, for each stalk
        '''
        # Get the center points of the stalks
        stalks_features = []
        for mask in masks:
            # Ensure the mask has the minimum number of pixels
            if np.count_nonzero(mask) < MINIMUM_MASK_AREA:
                continue

            # Swap x and y in the mask
            mask = np.swapaxes(mask, 0, 1)
            nonzero = np.nonzero(mask)

            # Get the top and bottom height values of the stalk
            # NOTE: bottom_y is the top of the mask in the image using openCV indexing
            bottom_y, top_y = nonzero[1].min(), nonzero[1].max()

            # Sample the depth from the top mask slice of the stalk
            depth_sampling_pixels = np.nonzero(mask[:, int(bottom_y): int(bottom_y + (FEATURE_POINT_PIXEL_OFFSET / 2))])

            # Only take nonzero values where y is within the top and bottom y values
            depths = depth_image[depth_sampling_pixels[1], depth_sampling_pixels[0]]

            # Invert the x and y values to "undo" the openCV indexing
            stalk_features = [Point(x=cls.camera_width - np.median(np.nonzero(mask[:, top_y])[0]),
                                    y=cls.camera_height - top_y, z=np.median(depths) / DEPTH_SCALE)]

            # For every FEATURE_POINT_PIXEL_OFFSET pixels, get the center point
            for y in range(bottom_y, top_y, FEATURE_POINT_PIXEL_OFFSET):
                # Find the average x value for nonzero pixels at this y value
                y_values = np.nonzero(mask[:, y])[0]

                # If there are no y pixels, simply skip this value
                if len(y_values) > 0:
                    # Sample the depth from this mask slice of the stalk
                    depth_sampling_pixels = np.nonzero(mask[:, int(y - (FEATURE_POINT_PIXEL_OFFSET / 2)): int(y + (FEATURE_POINT_PIXEL_OFFSET / 2))])

                    if len(depth_sampling_pixels[0]) > 0:
                        depths = depth_image[depth_sampling_pixels[1], depth_sampling_pixels[0]]
                        stalk_features.append(Point(x=cls.camera_width - np.median(y_values),
                                                    y=cls.camera_height - y, z=np.median(depths) / DEPTH_SCALE))

            # Sample the depth from the bottom mask slice of the stalk
            depth_sampling_pixels = np.nonzero(mask[:, int(top_y - (FEATURE_POINT_PIXEL_OFFSET / 2)): int(top_y)])
            depths = depth_image[depth_sampling_pixels[1], depth_sampling_pixels[0]]
            stalk_features.append(Point(x=cls.camera_width - np.median(np.nonzero(mask[:, bottom_y])[0]),
                                        y=cls.camera_height - bottom_y, z=np.median(depths) / DEPTH_SCALE))

            stalks_features.append(stalk_features)

        return stalks_features

    @classmethod
    def determine_best_stalk(cls, stalks: 'list[Stalk]') -> Stalk:
        '''
        Find the best stalk from a list of stalks.

        Parameters
            stalks (list): A list of stalks to cluster and average

        Returns
            Stalk: the best stalk
        '''
        def pt_distance(point1: Point, point2: Point):
            return math.sqrt((point1.x - point2.x)**2 + (point1.y - point2.y)**2)

        def distance(stalk1: Stalk, stalk2: Stalk):
            # For now, the distance between stalks is simply the y offset between the median y values of the stalks
            return abs(np.median([point.y for point in stalk1.cam_points]) - np.median([point.y for point in stalk2.cam_points]))

        # Only store the X and Y values of the positions
        # clustering = OPTICS(eps=0.1, metric=distance).fit(stalks)
        THRESHOLD = 0.1
        clustering_labels = [0]
        for stalk in stalks[1:]:
            min_distance = float('inf')
            min_cluster = 0
            for i in range(len(clustering_labels)):
                if distance(stalk, stalks[i]) < min_distance:
                    min_distance = distance(stalk, stalks[i])
                    min_cluster = clustering_labels[i]

            clustering_labels.append(min_cluster if min_distance < THRESHOLD else max(clustering_labels) + 1)

        clustering_labels = np.array(clustering_labels)

        # Find the cluster with the most points
        best_cluster = max(set(clustering_labels), key=lambda cluster: np.count_nonzero(clustering_labels == cluster))

        # Find where the best cluster is in the labels
        best_cluster_index = np.where(clustering_labels == best_cluster)[0]

        # Get the stalks in the best cluster
        best_stalks = [stalks[i] for i in best_cluster_index]

        return best_stalks[0]

    @classmethod
    def get_pcl(cls, image, depth_image, transformer):
        '''
        Get the point cloud

        Parameters
            image (sensor_msgs.msg.Image): The depth image

        Returns
            point_cloud (pcl PointCloud): The point cloud
        '''
        pcd = o3d.geometry.PointCloud.create_from_rgbd_image(
            o3d.geometry.RGBDImage.create_from_color_and_depth(
                o3d.geometry.Image(cls.cv_bridge.imgmsg_to_cv2(image, desired_encoding='bgr8')),
                o3d.geometry.Image(cls.cv_bridge.imgmsg_to_cv2(depth_image, desired_encoding='mono8')),
                depth_scale=DEPTH_SCALE, depth_trunc=DEPTH_TRUNC, convert_rgb_to_intensity=False),
            o3d.camera.PinholeCameraIntrinsic(
                transformer.width, transformer.height, transformer.intrinsic))

        return pcd

    @classmethod
    def transform_points_to_world(cls, stalks_features: 'list[list[Point]]', transformer: Transformer) -> 'list[list[Point]]':
        '''
        Transform the stalk features to the ground plane (using the robot base transform)

        Parameters
            stalk_features (list[list[Point]]): The center points of the stalks
            transformer (Transformer): The transformer

        Returns
            transformed_features (list[list[Point]]): The transformed features
        '''
        transformed_features = []
        for stalk in stalks_features:
            transformed_features.append([transformer.transform_cam_to_world(p) for p in stalk])

        return transformed_features

    @classmethod
    def ransac_ground_plane(cls, pointcloud):
        '''
        Find the ground plane using RANSAC

        Parameters
            pointcloud (o3d.geometry.PointCloud): The point cloud

        Returns
            plane (np.ndarray): The plane coefficients [A,B,C,D] for Ax+By+Cz+D=0
        '''
        # NOTE: Alternatively, use pointcloud.segment_plane from open3d

        A = 150
        B = 100
        C = 10
        colors = np.asarray(pointcloud.colors)
        # Find the brown points in the point cloud
        brown_points = np.array(pointcloud.points)[np.argwhere(np.logical_and(
            colors[2] < A, np.logical_and(abs(colors[0] - colors[1]) < B, np.maximum(colors[0], colors[1]) > C)))]

        # Find the plane using RANSAC
        plane = pyrsc.Plane()
        best_eq, best_inliers = plane.fit(brown_points, INLIER_THRESHOLD, MAX_RANSAC_ITERATIONS)

        return best_eq

    @classmethod
    def get_grasp_points_by_ransac(cls, stalks_features, pointcloud):
        '''
        Find a point closest to 1-3" from the ground plane for each stalk

        Parameters
            stalks_features (list[np.ndarray[Point]]): The center points of the stalks
            pointcloud (o3d.geometry.PointCloud): The point cloud

        Returns
            grasp_points ([[geometry_msgs.msg.Point, distance_to_ground]]):
                The best grasp points found for each stalk, and their distance to the ground plane
        '''
        # Find the ground plane
        plane = cls.ransac_ground_plane(pointcloud)

        # Find the point closest to 2" from the ground plane for each stalk
        # NOTE: This relies on the ground plane being horizontal. For non-horizontal, use point to plane distance
        goal_height = -plane[3] + 2
        grasp_points = []
        for stalk in stalks_features:
            best_point = min(stalk, key=lambda pt, goal_height=goal_height: abs(pt.z - goal_height))
            distance_to_ground = best_point.z - (-plane[3])
            grasp_points.append([best_point, distance_to_ground])

        return grasp_points

    @classmethod
    def combine_pointclouds(cls, pointclouds, transformers):
        '''
        Combine multiple point clouds into one using ICP and the given transformations

        Parameters
            pointclouds (list[o3d.geometry.PointCloud]): The point clouds

        Returns
            pointcloud (o3d.geometry.PointCloud): The combined point cloud
        '''
        # If ICP is needed
        transformations = []
        for pcl, transformer in zip(pointclouds[1:], transformers[1:]):
            # Find the predicted transformations between pcl and the first pointcloud
            trans_init = transformer.E @ np.linalg.inv(transformers[0].E)

            result = o3d.pipelines.registration.registration_icp(
                pcl, pointclouds[0], 0.05, trans_init,
                o3d.pipelines.registration.TransformationEstimationPointToPlane())
            transformations.append(result.transformation)

        # Combine the point clouds
        pointcloud = pointclouds[0]
        for pcl in pointclouds[1:]:
            # Transform the pointcloud to the frame of the first one if ICP is being used
            pcl.transform(transformations.pop())
            pointcloud.points.extend(pcl.points)

    @classmethod
    def run_realsense(cls):
        cls.driver_process = subprocess.Popen(DRIVER_COMMAND, stdout=subprocess.PIPE, shell=True, preexec_fn=os.setsid)

    @classmethod
    def stop_realsense(cls):
        if cls.driver_process is not None:
            os.killpg(os.getpgid(cls.driver_process.pid), signal.SIGTERM)
            cls.driver_process = None

    @classmethod
    def find_stalk(cls, req: GetStalkRequest) -> GetStalkResponse:
        '''
        Process a request to find the best stalk to grab

        Parameters
            req (GetStalkRequest): The request, with a number of frames to process and a timeout

        Returns
            GetStalkResponse: The response, with a message, the best stalk found, and # frames processed
        '''
        print('Received a request for {} frames with timeout {} seconds'.format(req.num_frames, req.timeout))
        cls.call_index += 1

        # Run the realsense camera driver if needed
        if RUN_REALSENSE_ON_REQUEST:
            cls.run_realsense()

        try:
            camera_info = rospy.wait_for_message(CAMERA_INFO, CameraInfo, timeout=2)
            if camera_info is None:
                raise rospy.ROSException
            cls.camera_height = camera_info.height
            cls.camera_width = camera_info.width
        except rospy.ROSException:
            print(colored('Camera info not found, so camera is likely not running!', 'red'))
            return GetStalkResponse(success='ERROR', num_frames=0)

        cls.image_index = -1
        start = rospy.get_rostime()
        frame_best_stalks: list[Stalk] = []
        transformers: list[Transformer] = []

        def image_depth_callback(image, depth_image):
            nonlocal frame_best_stalks, transformers

            transformer = Transformer(cls.tf_buffer.get_tf_buffer())
            cls.image_index += 1

            # Run the model
            masks, output, scores = cls.run_detection(image)

            cv_depth_image = cls.cv_bridge.imgmsg_to_cv2(depth_image, desired_encoding="passthrough")
            cv_depth_image = np.array(cv_depth_image, dtype=np.float32)

            # region Feature extraction
            stalks_features: list[list[Point]] = cls.get_features(masks, cv_depth_image)

            # Visualize the stalks features on the image
            if VISUALIZE:
                cv_image = cls.cv_bridge.imgmsg_to_cv2(image, desired_encoding='bgr8')
                features_image = cls.model.visualize(cv_image, output).astype(np.uint8)
                for stalk in stalks_features:
                    for point in stalk:
                        try:
                            cv.circle(features_image, (cls.camera_width - int(point.x), cls.camera_height - int(point.y)), 2, (0, 0, 255), -1)
                        except Exception as e:
                            print('Unable to put circle in stalk image', e)
                            break
                cls.visualizer.publish_item('masks', features_image)
                cv.imwrite('masks/output{}-{}.png'.format(cls.call_index, cls.image_index), features_image)

            # Transform the points
            stalks_features = cls.transform_points_to_world(stalks_features, transformer)

            # Turn these features into stalks
            stalks = []
            for stalk, score, mask in zip(stalks_features, scores, masks):
                cam_pts = [transformer.transform_world_to_cam_frame(p) for p in stalk]
                new_stalk = Stalk(points=stalk, cam_points=cam_pts, score=score, mask=mask)

                # Ensure the stalk is valid, in case RANSAC failed
                if new_stalk.is_valid():
                    stalks.append(new_stalk)
            # endregion

            # region Stalk selection
            # Filter out stalks that are not within the bounds of the camera
            valid_stalks: list[Stalk] = [s for s in stalks if s.is_within_bounds()]

            if len(valid_stalks) == 0:
                rospy.logwarn('No valid stalks detected on frame {} ({} total stalks found)'.format(cls.image_index, len(stalks)))
                cls.stop_realsense()
                return

            if VISUALIZE:
                cls.visualizer.new_frame()
                cls.visualizer.publish_item('features', stalks_features, marker_color=[255, 0, 0])
                for stalk in stalks:
                    cls.visualizer.publish_item('stalk_lines', stalk, marker_color=[255, 255, 0], marker_size=0.01)

            graspable_stalks: list[Stalk] = []

            # Order by grasping point coordinates instead of masks, to account for possible sporadic points
            # TODO: Wasn't reverse before but reverse seems right (left to right goes positive but we want right to left)
            ordered_right_to_left: list[Stalk] = sorted(valid_stalks, key=lambda stalk: np.median([p.y for p in stalk.cam_points]), reverse=True)

            # Iterate from the right to the left, eliminating stalks that are too close for the gripper to fit between
            graspable_stalks.append(ordered_right_to_left[0])
            for i in range(1, len(ordered_right_to_left)):
                is_free = True
                for j in range(0, i):
                    # NOTE: Temporary assertion
                    # assert ordered_right_to_left[i].horizontal_pos >= ordered_right_to_left[j].horizontal_pos

                    if min([pt.y for pt in ordered_right_to_left[i].cam_points]) - max([pt.y for pt in ordered_right_to_left[j].cam_points]) < GRIPPER_WIDTH and \
                            min([pt.x for pt in ordered_right_to_left[j].cam_points]) - max([pt.x for pt in ordered_right_to_left[i].cam_points]) < GRIPPER_LENGTH_PAST_STALK:
                        is_free = False
                        break

                if is_free:
                    graspable_stalks.append(ordered_right_to_left[i])

            # For the remaining stalks, weight by width, confidence, and height
            stalk_weights = []
            for i, stalk in enumerate(graspable_stalks):
                # Use the z coordinate in world frame
                mask_height = np.ptp([p.z for p in stalk.points])

                # Use the average width of the mask in the image
                mask = np.swapaxes(stalk.mask, 0, 1)
                nonzero = np.nonzero(mask)
                top_y, bottom_y = nonzero[1].min(), nonzero[1].max()
                widths = []

                for y in range(top_y, bottom_y, 10):
                    x = nonzero[0][np.where(nonzero[1] == y)]
                    if len(x) > 0:
                        widths.append(np.ptp(x))

                mask_width = np.mean(widths)

                # Use the y coordinate in camera frame
                distance_from_center = abs(np.mean([p.y for p in stalk.cam_points]))

                weight = (stalk.score ** 2) * mask_width * (math.pow(mask_height, 1/3)) * (1 - distance_from_center)

                # print('Stalk index {} has weight {}, score {}, height {}, width {} distance_from_center {} y {}'.format(
                #     i, weight, stalks[i].score, mask_height, mask_width, distance_from_center, stalk.cam_grasp_point.y))

                stalk_weights.append(weight)

            # endregion
            best_stalk = graspable_stalks[np.argmax(stalk_weights)]

            # NOTE: This actually cannot be unbound, since only one valid stalk will always be graspable
            frame_best_stalks.append(best_stalk)  # type: ignore

        # Setup the callback for the images and depth images
        cls.sub_images = KillableSubscriber(IMAGE_TOPIC, Image)
        cls.sub_depth = KillableSubscriber(DEPTH_TOPIC, Image)
        ts = ApproximateTimeSynchronizer(
            [cls.sub_images, cls.sub_depth], queue_size=5, slop=0.2)
        ts.registerCallback(image_depth_callback)

        # Continue until enough frames have been gathered, or the timeout has been reached
        while cls.image_index < req.num_frames and (rospy.get_rostime() - start).to_sec() + SERVICE_REQUEST_END_BUFFER_TIME < req.timeout:
            rospy.sleep(0.1)

        # Unregister the callback
        cls.sub_depth.unregister()
        cls.sub_images.unregister()
        del ts

        #  Cluster the stalks, find the best one, average it
        if len(frame_best_stalks) == 0:
            print(colored('No valid stalks detected in any frame for this service request, requesting a REPOSITION', 'red'))
            cls.stop_realsense()
            return GetStalkResponse(success='REPOSITION', num_frames=cls.image_index + 1)

        try:
            best_stalk = cls.determine_best_stalk(frame_best_stalks)
        except Exception as e:
            print(colored('WARNING: Best stalk determination failed, so using only the first frame.', 'red'))
            print(colored('Got error', 'white'), colored(e, 'red'))
            best_stalk = frame_best_stalks[0]

        print(colored('Found stalk with approximate position (X: {}, Y: {}, Z: {})'.format(
            np.mean([p.x for p in best_stalk.cam_points]), np.mean([p.y for p in best_stalk.cam_points]), np.mean([p.z for p in best_stalk.cam_points])), 'green'))

        # Stop the camera driver
        cls.stop_realsense()
        stalk_line_msg = line_msg(slope=Vector3(x=best_stalk.line.slope[0], y=best_stalk.line.slope[1], z=best_stalk.line.slope[2]),
                                  intercept=Vector3(x=best_stalk.line.intercept[0], y=best_stalk.line.intercept[1], z=best_stalk.line.intercept[2]))
        return GetStalkResponse(success='DONE', stalk=stalk_msg(stalk_line=stalk_line_msg),
                                confidence=best_stalk.score, num_frames=cls.image_index + 1)


if __name__ == '__main__':
    print('Starting stalk_detect node.')

    rospy.init_node('stalk_detect')

    detect_node = DetectNode()

    print(colored('Loaded model. Waiting for service calls...', 'green'))

    rospy.spin()
